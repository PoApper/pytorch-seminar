---
title: "Homework 3"
layout: post
use_math: true
tags: ["homework"]
---

<br/>

- due date: 2021-12-05 23:59 제출
  - pdf 또는 png 형식으로 제출할 것

💥 (Warning) 딥러닝을 이 세미나로 시작하는 사람이라면 P2, P3는 버거울 수 있다. 그러니 HW3는 일찍 시작하길 바란다.

### P1. Image Classification: CIFAR 10

[seminar3]({{"/2021/11/20/seminar-3.html" | relative_url}})에서 MNIST 데이터셋에 대한 Classification CNN을 구현했다. 이번에는 다른 비전 데이터셋인 CIFAR10을 사용해 Classficiation CNN을 구현해보자.

- 데이터셋: torch에서 제공하는 `torchvision.dataset.CIFAR10`을 사용한다.
- 한 epoch 마다 loss와 acc 값을 기록해 그래프로 그린다.
  - `matplotlib` 사용할 것
  - xlabel, ylabel, title 등을 명시할 것
  - 몇 iteration을 돌릴지는 본인이 결정한다.
  - 어떤 lr 값을 쓸지도 본인이 결정한다.
- 모델을 CPU에서 학습 시켰을 때와 GPU에서 학습 시켰을 때 시간 상의 차이가 있었는지 확인한다.

### P2. CNN Techniques

아래에 나열되는 CNN 모델에서의 Techniques들을 조사하고 요약한다. 각 테크닉이 어떤 맥락에서 등장했는지 어떤 강점을 가지고 있는지를 기술해야 한다.

- Weight Initialization
  - Xavier Initialization
  - He Initialization
- dropout
- batch initialization

추가로 위의 개념을 학습한 후에 위 개념을 사용해 P1 문제를 다시 해결한다. [torch.nn.init](https://pytorch.org/docs/stable/nn.init.html)과 [torch.nn.functional.dropout](https://pytorch.org/docs/stable/generated/torch.nn.functional.dropout.html)을 참고한다.

혼자 공부하면 어려울 수도 있으니 참고할 만한 자료를 첨부한다.

- [CS231n: Training Neural Networks, part I](https://www.youtube.com/watch?v=wEoyxE0GP2M&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)

### P3. CNN Architectures

다음 세미나 때 역사적인 CNN Architecture들을 살펴볼 예정이다. 세미나 전에 미리 예습하는 느낌으로 아래에 제시되는 Architecture들을 조사하고 요약한다. 마찬가지로 어떤 맥락에서 등장했는지, 이전 모델에서 무엇을 해결하기 위해 제시되었는지, 어떤 강점과 테크닉을 썼는지 기술해야 한다.

- AlexNet
- VGGNet
- GoogLeNet
- ResNet
  - seminar4에서 주요하게 다룰 예정이다. 미리 살펴만 보고 와도 좋다. 
  - seminar4에서 ResNet을 코드로 구현할 예정이다.

혼자 공부하면 어려울 수도 있으니 참고할 만한 자료를 첨부한다.

- [CS231n: CNN Architectures](https://www.youtube.com/watch?v=DAOcjicFr1Y&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
- [CNN Architectures](https://lynnshin.tistory.com/11)
