---
title: "Seminar 10: Transformer (이론)"
layout: post
use_math: true
tags: ["seminar"]
---

<br/>

이번 포스트는 지킬 블로그 포스트가 아닌 ppt 형태로 진행됩니다. 아래의 수업자료를 참조해주세요 🙏

[[material link]](https://github.com/PoApper/pytorch-seminar/blob/main/colab_notebooks/seminar10-Transformer-(1).pdf)

<br/>

ps. seminar10은 별도의 HW가 없습니다!! Transformer를 이해하는데 최선을 다해봅시다!

## references

- [딥러닝을 이용한 자연어 처리 입문](https://wikidocs.net/31379)
- [[NLP 논문 구현] pytorch로 구현하는 Transformer (Attention is All You Need)](https://cpm0722.github.io/pytorch-implementation/transformer)
- [[Transformer]-1 Positional Encoding은 왜 그렇게 생겼을까? 이유](https://velog.io/@gibonki77/DLmathPE)