---
title: "Seminar 3: MNIST CNN"
layout: post
use_math: true
tags: ["seminar"]
---

<br/>

ì´ë²ˆ ì„¸ë¯¸ë‚˜ë¶€í„° "ì»´í“¨í„° ë¹„ì „" ë¶„ì•¼ì— ëŒ€í•œ ì£¼ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì²«ë²ˆì§¸ ì£¼ì œëŠ” **<u>Classification</u>** ì…ë‹ˆë‹¤.

### í‚¤ì›Œë“œ

- CNN
  - Image Convolutions
- Classification Model Implementation: MNIST

<hr/>

## CNN

![MNIST-CNN](https://miro.medium.com/max/2059/1*SGPGG7oeSvVlV5sOSQ2iZw.png)

\<CNN; Convolution Neural Network\>ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë° íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ë‹¤. CNNì˜ ì²« ë¶€ë¶„ì€ Convoluyion Layerì˜ ì—°ì†ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ì´ Convolution LayerëŠ” **"kerenl"**ì´ë¼ëŠ” ì •ì‚¬ê°ì˜ ìœˆë„ìš°ì™€ ì´ë¯¸ì§€ë¥¼ Conv. ì—°ì‚°í•˜ì—¬ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•œë‹¤.

CNN ëª¨ë¸ì„ ì‚´í´ë³´ê¸° ì „ì— ì´ Image Convoluyionê³¼ kernelì´ë¼ëŠ” ë…€ì„ì— ëŒ€í•´ ì¢€ë” ì‚´í´ë³´ê³  ê°€ì. ì‚¬ì‹¤ ì´ë¯¸ì§€ì— ëŒ€í•œ Convolution ì—°ì‚°ì€ CNNì´ ì œì‹œë˜ê¸° ì´ì „ë¶€í„° ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ ì¡´ì¬í–ˆë˜ ê°œë…ì´ë‹¤. ëŒ€í‘œì ì¸ Image Convolution ë‘ ê°€ì§€ë¥¼ ì‚´í´ë³´ê³  ê°€ì.

### Image Convolutions

1\. **Gaussian Filter**

$$
\frac{1}{16} \begin{bmatrix}
  1 & 2 & 1 \\
  2 & 4 & 2 \\
  1 & 2 & 1
\end{bmatrix}
$$

ê°€ì¥ê°€ë¦¬ë¡œ ê°ˆìˆ˜ë¡ ê°’ì´ ì¤„ì–´ë“œëŠ” Gaussian FilterëŠ” 2D ê°€ìš°ì‹œì•ˆì„ 3x3ì˜ í–‰ë ¬ì— Discrete í•˜ê²Œ í‘œí˜„í•œ ê²ƒì´ë‹¤.

ì´ ë…€ì„ì„ ì´ë¯¸ì§€ì— ì ìš©í•˜ë©´ 

<div class="img-wrapper">
  <img src="{{ "/images/image-convolutions-1.png" | relative_url }}" width="100%">
</div>

í”íˆ ì´ë¯¸ì§€ë¥¼ ë¸”ëŸ¬ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ Gaussian Filterë¥¼ ì‚¬ìš©í•œë‹¤. ì´ëŸ° ë¸”ëŸ¬ ì²˜ë¦¬ëŠ” ì´ë¯¸ì§€ì— í¬í•¨ëœ noiseì˜ íš¨ê³¼ë¥¼ ì˜…ì–´ì§€ê²Œ ë§Œë“¤ì–´ noise robustí•œ ë¶„ì„ì„ í•˜ê¸° ìœ„í•´ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤. ~~ìì„¸í•œ ë‚´ìš©ì€ ì»´í“¨í„°ë¹„ì „(CSED539) ê³¼ëª©ì—ì„œ ë°°ìš¸ ìˆ˜ ìˆë‹¤ ğŸ‘~~

<br/>

2\. **Sobel Filter**

$$
\begin{bmatrix}
  -1 & 0 & 1 \\
  -2 & 0 & 2 \\
  -1 & 0 & 1
\end{bmatrix}
$$

ê°€ìš´ë°ê°€ 0ì´ê³ , í•œìª½ì´ ìŒìˆ˜, ë‹¤ë¥¸ìª½ì´ ì–‘ìˆ˜ì¸ **Sobel Filter**ëŠ” ì´ë¯¸ì§€ì˜ Edgeë¥¼ ê²€ì¶œí•˜ëŠ” í•„í„°ë‹¤. 

<div class="img-wrapper">
  <img src="{{ "/images/image-convolutions-2.png" | relative_url }}" width="100%">
</div>

ë³´í†µì€ ì´ë¯¸ì§€ì— Gaussian Filterë¡œ Gaussian smoothing í•œ í›„ì— Sobel Filterë¡œ Edge Detectionì„ ìˆ˜í–‰í•œë‹¤.

<br/>

ì‚¬ì‹¤ ìš°ë¦¬ê°€ ë°°ìš°ëŠ” ë”¥ëŸ¬ë‹ê³¼ëŠ” ê·¸ë ‡ê²Œ ê´€ë ¨ìˆëŠ” ë‚´ìš©ì€ ì•„ë‹ˆì—ˆì§€ë§Œ, Convolution Layerê°€ ì–´ë–¤ ë§¥ë½ì—ì„œ ë‚˜ì™”ëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ë ¤ê³  ì»´í“¨í„° ë¹„ì „ ì´ˆê¸°ì˜ ì´ë¡ ì„ ì ê¹ ê°€ì ¸ì™”ë‹¤. ìœ„ì˜ Image Convolution Filterë“¤ì€ ëª¨ë‘ ì´ë¯¸ì§€ë¥¼ noise-robustí•˜ê²Œ ë§Œë“¤ê±°ë‚˜(Gaussian Filter), ì´ë¯¸ì§€ì˜ Edgeë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜(Sobel Filter) ë“±ì˜ ì—­í• ì„ í•´ì™”ë‹¤. ì¦‰, ì´ë¯¸ì§€ë¥¼ ê°€ê³µí•˜ê±°ë‚˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë„êµ¬ë¡œ ì‚¬ìš©ë˜ì–´ ì™”ë‹¤ëŠ” ê²ƒì´ë‹¤. 

ìš°ë¦¬ê°€ CNNì—ì„œ ì‚¬ìš©í•˜ëŠ” Convolution Layerë„ ì´ í•„í„°ë“¤ê³¼ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šë‹¤. ì´ë¯¸ì§€ë¥¼ ì“°ê¸° í¸í•˜ê²Œ ê°€ê³µí•˜ê±°ë‚˜ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•œë‹¤. ë‹¤ë§Œ, ì»´í“¨í„° ë¹„ì „ ì´ˆê¸°ì™€ ë”¥ëŸ¬ë‹ì˜ Convolution Layerê°€ ë‹¤ë¥¸ ì ì€ Gaussian/Sobel FilterëŠ” ëª©ì ì— ë”°ë¼ ì •í•´ì§„ ê°’ì´ ìˆëŠ” í•„í„°ë¼ëŠ” ê²ƒì´ê³ , ë”¥ëŸ¬ë‹ì˜ Convolution LayerëŠ” ìš°ë¦¬ê°€ ë³„ë„ë¡œ ê°’ì„ ì •í•´ì£¼ì§€ ì•Šì•„ë„ ë”¥ëŸ¬ë‹ í•™ìŠµì— ì˜í•´ Convolution Filterì˜ ê°’ì´ í•™ìŠµëœë‹¤ëŠ” ê²ƒì´ë‹¤. ğŸ‘

<br/>

## Let's CNN

![MNIST-CNN](https://miro.medium.com/max/2059/1*SGPGG7oeSvVlV5sOSQ2iZw.png)

ì! ì´ì œ CNN ëª¨ë¸ì„ pytorchë¡œ êµ¬í˜„í•´ë³´ì. ì—¬ëŸ¬ë¶„ì´ HW2ë¥¼ ì˜ í’€ì–´ì™”ë‹¤ë©´ğŸ‘€ CNNì˜ Conv Layer, Pooling, Padding ë“±ì€ ì´ë¯¸ ì•Œê³  ìˆì„ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‹ˆ ì„¤ëª…ì€ ìƒëµí•˜ê³  ë°”ë¡œ CNN ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ì!

ë¨¼ì € PyTorchì˜ Conv. Layerì¸ `nn.Conv2d()`ì— ëŒ€í•´ ì‚´í´ë³´ì. 

```py
nn.Linear(in_features, out_features)
nn.Conv2d(in_features, out_features, kernel_size)
```

`nn.Conv2d()`ë„ `nn.Linear()`ì²˜ëŸ¼ ì…ë ¥ í”¼ì²˜ ìˆ˜ì™€ ì¶œë ¥ í”¼ì²˜ ìˆ˜ë¥¼ ì¸ìë¡œ ë°›ëŠ”ë‹¤. ë‹¤ë§Œ, `Conv2d()`ëŠ” kernel ì‚¬ì´ì¦ˆë¥¼ ì •í•´ì¤˜ì•¼ í•˜ë¯€ë¡œ ì¶”ê°€ë¡œ `kernel_size`ê°€ í•„ìš”í•˜ë‹¤.

```py
nn.Conv2d(1, 1, 5) # í‘ë°± ì´ë¯¸ì§€ë¥¼ í‘ë°± ì´ë¯¸ì§€ë¡œ
nn.Conv2d(3, 3, 5) # ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ
nn.Conv2d(1, 6, 5) # í‘ë°± ì´ë¯¸ì§€ë¥¼ 6ì±„ë„ì˜ ì´ë¯¸ì§€ë¡œ
```

ì! ê·¸ëŸ¼ PyTorch `nn.Conv2d()`ë¥¼ ì•Œì•˜ìœ¼ë‹ˆ CNN ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì! ì´ë²ˆì—ëŠ” PyTorchì˜ `nn.Module`ì„ ìƒì†ë°›ëŠ” ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³¼ ê²ƒì´ë‹¤.

```py
import torch.nn as nn

class MyCNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 5)
    self.conv2 = nn.Conv2d(6, 16, 5)

  def forward(self, x):
    x = self.conv1(x)
    x = self.conv2(x)
    return x
```
 
ìœ„ì˜ ì½”ë“œëŠ” 2ê°œì˜ Conv layerë¡œ êµ¬ì„±ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬í˜„í•œ ê²ƒì´ë‹¤. PyTorch ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ë§Œë“¤ ë•ŒëŠ” `nn.Module`ì„ ìƒì† ë°›ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ë©´ ëœë‹¤. ì´ë•Œ, `__init__()`ì—ëŠ” ì‚¬ìš©í•  nn layerë“¤ì„ ì •ì˜í•˜ê³ , `forward()`ì—ëŠ” ëª¨ë¸ì— ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•œë‹¤.

ê³„ì† CNN ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ì. 2ë²ˆì˜ Conv layer ì‚¬ì´ì—ëŠ” Pooling Layerë¥¼ ë¶™ì—¬ì¤€ë‹¤. PyTorchì˜ `F.max_pool2d()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

```py
# add pooling layer
import torch.nn.functional as F

class MyCNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 5)
    self.conv2 = nn.Conv2d(6, 16, 5)

  def forward(self, x):
    x = self.conv1(x)
    x = F.max_pool2d(x)
    x = self.conv2(x)
    x = F.max_pool2d(x)
    return x
```

`max_pool2d(tensor, kernel_size)`ì€ weight/bias ê°™ì€ í•™ìŠµí•  íŒŒë¼ë¯¸í„°ê°€ ì—†ê¸° ë•Œë¬¸ì— `__init__()`ì— ì •ì˜í•˜ì§€ ì•Šê³   `forward()`ì— ë°”ë¡œ ì •ì˜í•´ì„œ ì“°ë©´ ëœë‹¤.

ë‹¤ìŒì€ Conv layer ë‹¤ìŒì˜ FC layerë¥¼ êµ¬í˜„í•˜ì. [seminar2]({{"/2021/11/07/seminar-2.html" | relative_url}})ì—ì„œ ë°°ìš´ `nn.Linear()`ë¥¼ ì“°ë©´ ëœë‹¤.

```py
class MyCNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 5)
    self.conv2 = nn.Conv2d(6, 16, 5)
    self.fc1 = nn.Linear(16 * 4 * 4, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)

  def forward(self, x):
    x = self.conv1(x)
    x = F.max_pool2d(x, 2)
    x = self.conv2(x)
    x = F.max_pool2d(x, 2)

    x = torch.flatten(x, 1)
    x = self.fc1(x)
    x = self.fc2(x)
    x = self.fc3(x)
    return x
```

ì™œ `fc1`ì˜ `in_features`ê°€ `16 * 4 * 4`ì´ê³ , `fc3`ì˜ `out_features`ê°€ `10`ì¼ê¹Œ ì‹¶ì„ ê²ƒì´ë‹¤. 

![MNIST](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/320px-MnistExamples.png)

ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ê°€ MNIST ë°ì´í„°ì…‹ìœ¼ë¡œ 0~9 ìˆ«ìë¥¼ ë¶„ë¥˜í•˜ëŠ” CNN ëª¨ë¸ì„ ë§Œë“¤ ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤. MNIST ë°ì´í„°ë¥¼ `conv2`ê¹Œì§€ ì²˜ë¦¬í•˜ë©´ `4 x 4 x 16`ì˜ í…ì„œê°€ ë˜ê³ , ë§ˆì§€ë§‰ì— 0~9 ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ ë¶„ë¥˜í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ `fc3`ì˜ `out_features`ë¥¼ `10`ìœ¼ë¡œ ì„¤ì •í•œë‹¤.

`forward()` ë¶€ë¶„ì—ì„œ FC layerì— ë„£ê¸° ì „ì— `torch.flatten(x, 1)`ì„ ì“°ëŠ”ë°, `H  x W x C`ë¡œ ëœ í…ì„œë¥¼ `H * W * C`ë¡œ ë‚©ì‘í•˜ê²Œ ë§Œë“œëŠ” í•¨ìˆ˜ë‹¤.

ì´ì œ CNNì˜ í°í‹€ì€ ì™„ì„±í•œ ìƒíƒœë‹¤. ë‚¨ì€ ê²ƒì€ ReLU layerë‹¤. ê° layerì˜ ì¶œë ¥ì— `F.relu()`ë¡œ ReLU functionì„ ë„£ì£¼ì.

```py
class MyCNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 5)
    self.conv2 = nn.Conv2d(6, 16, 5)
    self.fc1 = nn.Linear(16 * 4 * 4, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)

  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.max_pool2d(x, 2)
    x = F.relu(self.conv2(x))
    x = F.max_pool2d(x, 2)

    x = torch.flatten(x, 1)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return x
```

ì¢Œìì”! ì—¬ëŸ¬ë¶„ì€ ì²« CNN ëª¨ë¸ì„ êµ¬í˜„í•œ ê²ƒì´ë‹¤! ğŸ‘ ëª¨ë¸ì´ ì˜ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤. ìš°ë¦¬ëŠ” MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤.

## TorchVision: MNIST

PyTorchëŠ” MNISTì™€ ê°™ì´ ìœ ëª…í•œ ë°ì´í„°ì…‹ì„ ì‰½ê²Œ ì“¸ ìˆ˜ ìˆë„ë¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µí•œë‹¤. ë¹„ì „ ìª½ ë°ì´í„°ëŠ” `torchvision.datasets`ì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. [torchvision.datasets](https://pytorch.org/vision/stable/datasets.html)

ìš°ë¦¬ëŠ” torchvisionì—ì„œ ì œê³µí•˜ëŠ” MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤. [torchvision.dataset.MNIST](https://pytorch.org/vision/stable/datasets.html#mnist) ëª…ì„¸ë¥¼ ì˜ ì½ì–´ë³´ë©´ `root`, `train`, `download`, `transform` ë“±ì˜ ì¸ìê°€ ìˆë‹¤. ì¼ë‹¨ì€ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ë°ì´í„°ë¥¼ ì–»ì.

```py
import torchvision

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True)
testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True)

print(len(trainset))
print(len(testset))
```

ê·¸ëŸ¬ë©´ `./data` í´ë”ì— MNIST ë°ì´í„°ì…‹ì´ ì €ì¥ëœë‹¤. ê·¸ë¦¬ê³  ë³„ë„ë¡œ Custom Datasetì„ ì •ì˜í•  í•„ìš”ì—†ì´ `torchvision`ì—ì„œ ì œê³µí•˜ëŠ” MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë©´ ëœë‹¤! ğŸ‘

MNIST ë°ì´í„°ê°€ ì˜ ë°›ì•„ì¡ŒëŠ”ì§€ í™•ì¸í•´ë³´ì.

```py
image, label = trainset[0]
print(image, label)
display(image)
```

<br/>

`DataLoader`ë„ ì •ì˜í•˜ì.

```py
from torch.utils.data import DataLoader

batch_size = 4

train_dl = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_dl = DataLoader(testset, batch_size=batch_size, shuffle=False)
```

## Train CNN Model!

ì! ì´ì œ ë°ì´í„°ì…‹ë„ ì¤€ë¹„ë˜ì—ˆìœ¼ë‹ˆ CNN ëª¨ë¸ì„ í•™ìŠµì‹œì¼œë³´ì! ğŸ‘ ê·¸ëŸ°ë° ë³¸ê²©ì ì¸ í•™ìŠµ í”Œë¡œìš°ë¥¼ ë§Œë“¤ê¸° ì „ì— ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì´ ì˜ ë¶™ëŠ”ì§€ ë””ë²„ê¹…ì„ ë¨¼ì € í•´ì•¼ í•œë‹¤. ~~ë””ë²„ê¹… ê¼­ í•´ì•¼ í•œë‹¤...~~

```py
# ë””ë²„ê¹… ë¨¼ì €!
image, label = trainset[0]

myCNN = MyCNN()
myCNN(image)
```

ë°ì´í„°ì…‹ì„ ë°”ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ `image` ê°ì²´ê°€ tensorê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì˜¤ë¥˜ë¥¼ ë±‰ëŠ”ë‹¤.

```py
# ë””ë²„ê¹… ë¨¼ì €!
import numpy as np
image, label = trainset[0]
image = np.array(image)
image = torch.Tensor(image)

myCNN = MyCNN()
myCNN(image)
```

tensorë¡œ ë°”ê¿”ì¤˜ë„ ì˜¤ë¥˜ê°€ ë‚  í…ë°, (1) í‘ë°± ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ì„ ê²ƒì´ë‹ˆ `1 x W x H`ì˜ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì•¼ í•œë‹¤ (2) ë°°ì¹˜ ì°¨ì› ì¶”ê°€ `B x 1 x W x H`ë¥¼ ì•ˆ í•´ì¤¬ê¸° ë•Œë¬¸ì´ë‹¤.

```py
# ë””ë²„ê¹… ë¨¼ì €!
import numpy as np

image, label = trainset[0]

image = np.array(image)
print(type(image), image.shape)

image = torch.Tensor([image])
print(type(image), image.shape)

image = image.unsqueeze(0)
print(type(image), image.shape)

myCNN = MyCNN()
myCNN(image)
```

ì¶œë ¥ ê²°ê³¼ë¡œ ì•„ë˜ì™€ ê°™ì´ 10ì°¨ì›ì˜ í…ì„œë¥¼ ë±‰ìœ¼ë©´ ëª¨ë¸ì´ ì˜ êµ¬ì¶•ëœ ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤! ğŸ‘

```
tensor([[ 2.2457, -5.4209, -3.1778,  1.5650, -0.3050,  2.3941, -1.7845, -1.9811,
         -3.0732,  3.0183]], grad_fn=<AddmmBackward0>)
torch.Size([1, 10])
```

<br/>

ê·¸ëŸ°ë° ì ê¹! ë°©ê¸ˆì˜ ë””ë²„ê·¸ì—ì„œ ìš°ë¦¬ëŠ” `trainset[0]`ì˜ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ Tensorë¡œ ë°”ê¾¸ê³ , í‘ë°± ì´ë¯¸ì§€ë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•´ `1 x W x H`ë¡œ ë³€í™˜ë„ í–ˆë‹¤. ì‚¬ì‹¤ ì´ ê³¼ì •ì„ ì§ì ‘ í•˜ì§€ ì•Šê³ , trainsetì„ êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì—ì„œ ë°”ë¡œ í•  ìˆ˜ë„ ìˆëŠ”ë°... `torchvision.transforms`ì„ ì“°ë©´ ëœë‹¤! ğŸ‘

```py
import torchvision.transforms as transforms

transform = transforms.ToTensor()

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)

image, label = trainset[0]
print(type(image), image.shape)
print(label)
```

ì½”ë“œë¥¼ ë³´ë©´ MNIST ë°ì´í„°ì…‹ì— `transform` ì¸ìë¡œ `ToTensor()`ë¥¼ ë„£ì–´ì¤¬ë‹¤. ì´ë¥¼ í†µí•´ ì´ë¯¸ì§€ì— ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì§ì ‘ ìˆ˜í–‰í•˜ì§€ ì•Šê³ , ì½œë°± í•¨ìˆ˜ í˜•íƒœë¡œ ë„˜ê¸¸ ìˆ˜ ìˆë‹¤!

<br/>

ì‚¬ì‹¤ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬, ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë‹¨ê³„ê°€ í•˜ë‚˜ ë” ë‚¨ì•˜ëŠ”ë° ë°”ë¡œ Normalizationì´ë‹¤. seminar2ì—ì„œ Linear Regressionì„ êµ¬í˜„í•  ë•Œë„ Normalizationì„ ìˆ˜í–‰í–ˆëŠ”ë° ê·¸ê±¸ ì´ë¯¸ì§€ ë°ì´í„°ì— ëŒ€í•´ì„œë„ í•œë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. `transform`ì„ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•˜ë©´ ì´ë¯¸ì§€ë¥¼ Normalize í•œë‹¤.

```py
import torchvision.transforms as transforms

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)

image, label = trainset[0]
print(type(image), image.shape)
print(label)
```

ë³´ë©´ `transforms.Compose()`ë€ ê±¸ ì¼ëŠ”ë° ì—¬ëŸ¬ ê°œì˜ ì „ì²˜ë¦¬ ê³¼ì •ì„ ë¬¶ê³  ì‹¶ì„ ë•Œ ì“°ëŠ” ë…€ì„ì´ë‹¤.

ì´ì œ ì •ë§ë¡œ ë””ë²„ê·¸ëŠ” ëë‚¬ë‹¤!! ~~ì›ë˜ ì´ë ‡ê²Œ ì‹ ê²½ ì¨ì¤„ê²Œ ë§ë‹¤ ã… ã… ~~ ìœ„ ê³¼ì •ì—ì„œ í–ˆë˜ `transform`ì„ ê¸°ì¡´ì˜ trainset/testsetê³¼ dataloaderì—ë„ ì ìš©í•˜ê³  ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì!

### ë””ë²„ê·¸ ë! ì§„ì§œ ëª¨ë¸ í•™ìŠµ!

ì €ë²ˆ seminr2ì˜ ë§ˆì§€ë§‰ì— ë´¤ë˜ ë”¥ëŸ¬ë‹ í•™ìŠµ í”Œë¡œìš°ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¼ê°€ë©´ ëœë‹¤.

```py
# prepare dataset
data = df.read_csv(...)

# create custom dataset class
class MyDataset(Dataset):
  ...

# build DL model
model = nn.Linear(...)

# prepare dataloader
dl_train = DataLoader(...)

# prepare optimizer
optimizer = optim.SGD(...)

# Do SGD
for epoch in range(MAX_EPOCH):
  # train phase
  for X, y in dl_train:
    y_pred = model(X)
    loss = ...

    # Back-prop
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  # eval phase
  evaluate(dl_train)
  evaluate(dl_val)
  evaluate(dl_test)
```

ì´ë²ˆì—ëŠ” ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ê¸° ë–„ë¬¸ì— Loss Functionìœ¼ë¡œ `nn.CrossEntropyLoss()`ë¥¼ ì‚¬ìš©í•œë‹¤. ë¶„ë¥˜ ëª¨ë¸ì˜ Lossì— ëŒ€í•´ì„  ì´ë¯¸ ì•Œê³  ìˆì„ ê±°ë¼ ìƒê°í•˜ê³  ë”°ë¡œ ì„¤ëª…í•˜ì§„ ì•Šê² ë‹¤ ğŸ‘

```py
# prepare dataset
# ìœ„ì—ì„œ í–ˆìŒ.

# build DL model
# ì»¤ìŠ¤í…€ ëª¨ë¸ ì •ì˜ëŠ” ìœ„ì—ì„œ í–ˆìŒ.
myCNN = MyCNN()

# prepare dataLoader
# ìœ„ì—ì„œ í–ˆìŒ.

# prepare optimizer
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(myCNN.parameters(), lr=0.001, momentum=0.9)

# Train Model!
...
```

ì ì´ì œ ëª¨ë¸ í•™ìŠµ ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ì§œë©´...

```py
# Train Model!
MAX_EPOCH = 101
for epoch in range(MAX_EPOCH):
  total_loss = 0
  for X, y in train_dl:
    optimizer.zero_grad()

    y_pred = myCNN(X)
    
    loss = criterion(y_pred, y)
    total_loss += loss.item()

    loss.backward()
    optimizer.step()
  print(f'[epoch {epoch}]: {total_loss / len(trainset):.4f}')
```

ê°€ ë˜ëŠ”ë°, ì‹¤ì œë¡œ í•™ìŠµ ëŒë ¤ë³´ë©´ 100 epochì„ ë„ëŠ”ë° ì‹œê°„ì´ ê½¤ ê±¸ë¦°ë‹¤... ê·¸ ì´ìœ ëŠ” `batch_size`ì™€ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ì¸ë° ì½”ë“œë¥¼ ì•½ê°„ ìˆ˜ì •í•˜ì.

1\. `batch_size` ì¡°ì •

```py
batch_size = 64
train_dl = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_dl = DataLoader(testset, batch_size=batch_size, shuffle=False)

# Train Model!
MAX_EPOCH = 101
for epoch in range(MAX_EPOCH):
  total_loss = 0
  for X, y in train_dl:
    optimizer.zero_grad()

    y_pred = myCNN(X)
    
    loss = criterion(y_pred, y)
    total_loss += loss.item()

    loss.backward()
    optimizer.step()
  print(f'[epoch {epoch}]: {total_loss / len(trainset):.4f}')
```

2\. GPUë¡œ ëª¨ë¸ í•™ìŠµ

```py
myCNN = MyCNN()
myCNN = myCNN.cuda()
optimizer = optim.SGD(myCNN.parameters(), lr=0.001, momentum=0.9)

# Train Model!
MAX_EPOCH = 101
for epoch in range(MAX_EPOCH):
  total_loss = 0
  for X, y in train_dl:
    optimizer.zero_grad()
    X = X.cuda()
    y = y.cuda()

    y_pred = myCNN(X)
    
    loss = criterion(y_pred, y)
    total_loss += loss.item()

    loss.backward()
    optimizer.step()
  print(f'[epoch {epoch}]: {total_loss / len(trainset):.4f}')
```

ì´ ë‹¨ê³„ì—ì„œ ì ì ˆí•œ `batch_size`ëŠ” Colabì˜ "ëŸ°íƒ€ì„ -> ì„¸ì…˜ ê´€ë¦¬" íƒ­ì˜ GPU ì‚¬ìš©ëŸ‰ì„ ë³´ê³  GPU ì˜¤ë²„ê°€ ë‚˜ì§€ ì•Šì„ ì •ë„ë¡œ í•´ì„œ ì˜ ì¡°ì •í•˜ë©´ ëœë‹¤ ğŸ˜‰

ì! ê·¸ëŸ¼ ì´ì œ train/test ì„±ëŠ¥ ì¸¡ì •ê¹Œì§€ í¬í•¨í•´ ëª¨ë¸ì„ ì™„ì„±í•´ë³´ì. ì´ë²ˆì—ëŠ” val setì€ ìš´ìš©í•˜ì§€ ì•Šê² ë‹¤ ğŸ™

```py
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torch.optim as optim

USE_CUDA = True

# prepare dataset
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 1)])
trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
# build DL model
class MyCNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 5)
    self.conv2 = nn.Conv2d(6, 16, 5)
    self.fc1 = nn.Linear(16 * 4 * 4, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)

  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.max_pool2d(x, 2)
    x = F.relu(self.conv2(x))
    x = F.max_pool2d(x, 2)

    x = torch.flatten(x, 1)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return x

myCNN = MyCNN()
if USE_CUDA:
  myCNN = myCNN.cuda()

# prepare dataLoader
BATCH_SIZE = 128
train_dl = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
test_dl = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)

# prepare optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(myCNN.parameters(), lr=0.001, momentum=0.9)

# Train Model!
total_tic = time.time()
# Train Model!
MAX_EPOCH = 21
for epoch in range(MAX_EPOCH):
  tic = time.time()

  # train
  total_train_loss = 0
  total_train_correct = 0
  for X, y in train_dl:
    optimizer.zero_grad()
    if USE_CUDA:
      X = X.cuda()
      y = y.cuda()

    y_pred = myCNN(X)

    value, index_pred = torch.max(y_pred.data, 1)
    total_train_correct += (index_pred == y).sum().item()
    
    loss = criterion(y_pred, y)
    total_train_loss += loss.item()

    loss.backward()
    optimizer.step()

  # test
  total_test_loss = 0
  total_test_correct = 0
  with torch.no_grad():
    for X, y in test_dl:
      if USE_CUDA:
        X = X.cuda()
        y = y.cuda()

      y_pred = myCNN(X)

      value, index_pred = torch.max(y_pred.data, 1)
      total_test_correct += (index_pred == y).sum().item()
      
      loss = criterion(y_pred, y)
      total_test_loss += loss.item()

  toc = time.time()
  print(f'===== {epoch} ====')
  print(f'elaps: {toc - tic:.1f} sec')
  print(f'[train] loss: {total_train_loss / len(trainset):.4f}, acc: {total_train_correct / len(trainset):.3f}')
  print(f'[test] loss: {total_test_loss / len(testset):.4f}, acc: {total_test_correct / len(testset):.3f}')
total_toc = time.time()

print(f'[Total Run]: {total_toc - total_tic:.1f} sec')
```

booleanì˜ `USE_CUDA`ë¥¼ ì¶”ê°€í•´ ì†ì‰½ê²Œ CPU/GPU ìŠ¤ìœ„ì¹­ í•  ìˆ˜ ìˆë„ë¡ ì½”ë“œë¥¼ êµ¬ì„±í–ˆë‹¤ ğŸ™ ë³¸ë˜ëŠ” Loss ê·¸ë˜í”„ì™€ Acc ê·¸ë˜í”„ê¹Œì§€ ê·¸ë ¤ì•¼ í•˜ì§€ë§Œ ê·¸ ë¶€ë¶„ì€ ìˆ™ì œë¡œ ë‚¨ê²¨ë‘ê² ë‹¤ ğŸ˜‰

<hr/>

## ë§ºìŒë§

ì˜¤ëŠ˜ ìš°ë¦¬ê°€ êµ¬í˜„í•œ ëª¨ë¸ì€ [LeNet(Yann LeCun, 1989)](https://en.wikipedia.org/wiki/LeNet) ëª¨ë¸ë¡œ ìµœì´ˆë¡œ CNN êµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ ë¬¸ì œë¥¼ í•´ê²°í•œ ëª¨ë¸ì´ë‹¤. ì˜¤ëŠ˜ì˜ ì½”ë“œ ì—­ì‹œ LeNetì˜ êµ¬ì¡°ë¥¼ ë”°ë¼ ì‘ì„±ë˜ì—ˆë‹¤. LeNet ë…¼ë¬¸ì„ ì½ì–´ë³¼ í•„ìš”ëŠ” ì—†ë‹¤. ë‹¤ë§Œ, HWì—ì„œ LeNet ì´í›„ì˜ CNN Architectureì— ëŒ€í•œ ë‚´ìš©ë“¤ì„ ê³µë¶€í•˜ëŠ” ê²ƒì´ ê³¼ì œë¡œ ë‚˜ê°ˆ ì˜ˆì •ì´ë‹¤.

ë‹¤ìŒ ì„¸ë¯¸ë‚˜ì—ì„œëŠ” VGG, ResNet ë“± CNN Architectureì— ëŒ€í•´ ì‚´í´ë³´ë„ë¡ í•˜ê² ë‹¤.

<hr/>

## References

- [Week 4: Image Filtering and Edge Detection](https://sbme-tutorials.github.io/2018/cv/notes/4_week4.html)
- [PyTorch - max_pool2d](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html)
- [torchvision.datasets](https://pytorch.org/vision/stable/datasets.html)
- [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)